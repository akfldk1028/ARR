# MAS + ë²•ë¥  ê²€ìƒ‰ ì‹œìŠ¤í…œ í†µí•© ê³„íš

## ğŸ¯ ëª©í‘œ

**ì—„ì²­ë‚œ ì–‘ì˜ PDF ë¬¸ì„œ** + **MAS (Multi-Agent System)** + **RNE/INE ë²•ë¥  ê²€ìƒ‰**ì„ ê²°í•©í•˜ì—¬ ì§€ëŠ¥í˜• ë²•ë¥  ìë¬¸ ì‹œìŠ¤í…œ êµ¬ì¶•

---

## ğŸ“Š í˜„ì¬ ìƒí™© ë¶„ì„

### í˜„ì¬ ì‹œìŠ¤í…œ êµ¬ì„±

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Frontend (Chat Interface)                                  â”‚
â”‚  - í…ìŠ¤íŠ¸ ì±„íŒ… (chat/)                                        â”‚
â”‚  - ìŒì„± ì±„íŒ… (gemini/)                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚ WebSocket
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  MAS (Multi-Agent System)                                   â”‚
â”‚  - GeneralWorker: ì¼ë°˜ ì¡°ì •ì                                â”‚
â”‚  - FlightSpecialist: í•­ê³µê¶Œ ì „ë¬¸ê°€                            â”‚
â”‚  - A2A Protocol: ì—ì´ì „íŠ¸ ê°„ í†µì‹                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Law Search System (ë³„ë„)                                    â”‚
â”‚  - RNE/INE ì•Œê³ ë¦¬ì¦˜                                          â”‚
â”‚  - Neo4j (2,987 HANG ë…¸ë“œ)                                   â”‚
â”‚  - 3ê°œ PDF (ë²•ë¥ , ì‹œí–‰ë ¹, ì‹œí–‰ê·œì¹™)                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**ë¬¸ì œì **:
- âŒ MASì™€ ë²•ë¥  ê²€ìƒ‰ì´ ë¶„ë¦¬ë¨
- âŒ 3ê°œ PDFë§Œ ì²˜ë¦¬ (í™•ì¥ì„± ì—†ìŒ)
- âŒ ì—ì´ì „íŠ¸ê°€ ë²•ë¥  ê²€ìƒ‰ ê¸°ëŠ¥ ì‚¬ìš© ë¶ˆê°€
- âŒ ëŒ€ëŸ‰ PDF ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì—†ìŒ

---

## ğŸ’¡ í†µí•© ì•„ì´ë””ì–´

### 1. LawSpecialist Agent ì¶”ê°€

**ì—­í• **: ë²•ë¥  ì „ë¬¸ê°€ ì—ì´ì „íŠ¸
- ë²•ë¥  ê²€ìƒ‰ (RNE/INE)
- ë²•ë¥  í•´ì„ & ìë¬¸
- ê´€ë ¨ ì¡°í•­ ì¶”ì²œ
- íŒë¡€ ì—°ê²° (í–¥í›„)

**ê¸°ì¡´ MASì™€ í†µí•©**:
```
ì‚¬ìš©ì: "ë„ì‹œê³„íš ê´€ë ¨ ë²•ê·œ ì•Œë ¤ì¤˜"
  â†“
GeneralWorker (ì¡°ì •ì)
  â†“ A2A í”„ë¡œí† ì½œ
LawSpecialist (ë²•ë¥  ì „ë¬¸ê°€)
  â†“ RNE/INE
Neo4j (ë²•ë¥  DB)
  â†“ ê²°ê³¼ ë°˜í™˜
GeneralWorker â†’ ì‚¬ìš©ì
```

---

### 2. ëŒ€ëŸ‰ PDF ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸

**í˜„ì¬**: 3ê°œ PDF ìˆ˜ë™ ì²˜ë¦¬
**ëª©í‘œ**: ìˆ˜ì²œ ê°œ PDF ìë™ ì²˜ë¦¬

**íŒŒì´í”„ë¼ì¸ ì„¤ê³„**:
```
PDF í´ë” (ìˆ˜ì²œ ê°œ)
  â†“ [Step 1] PDF â†’ JSON
  â”œâ”€â†’ pdf_extractor.py (ê¸°ì¡´)
  â”œâ”€â†’ law_parser_improved.py (ê¸°ì¡´)
  â””â”€â†’ ë³‘ë ¬ ì²˜ë¦¬ (multiprocessing)
  â†“
JSON íŒŒì¼ë“¤ (êµ¬ì¡°í™”)
  â†“ [Step 2] JSON â†’ Neo4j
  â”œâ”€â†’ json_to_neo4j.py (ê¸°ì¡´)
  â”œâ”€â†’ ë°°ì¹˜ ì²˜ë¦¬ (bulk import)
  â””â”€â†’ ì¤‘ë³µ ì œê±°
  â†“
Neo4j (ìˆ˜ë§Œ ê°œ ë…¸ë“œ)
  â†“ [Step 3] ì„ë² ë”© ìƒì„±
  â”œâ”€â†’ add_embeddings.py (ê¸°ì¡´)
  â”œâ”€â†’ GPU ê°€ì† (ì„ íƒ)
  â””â”€â†’ ìºì‹±
  â†“
ê²€ìƒ‰ ê°€ëŠ¥í•œ ë²•ë¥  DB
```

---

## ğŸ” ìˆœì°¨ì  í†µí•© ê³„íš

### Phase 1: LawSpecialist Agent ê°œë°œ (1ì£¼)

**ëª©í‘œ**: MASì— ë²•ë¥  ì „ë¬¸ê°€ ì¶”ê°€

#### 1.1 íŒŒì¼ ìƒì„±

```
agents/worker_agents/
â”œâ”€â”€ implementations/
â”‚   â””â”€â”€ law_specialist_worker.py  â† ìƒˆë¡œ ìƒì„±
â””â”€â”€ cards/
    â””â”€â”€ law_specialist_agent.json  â† ìƒˆë¡œ ìƒì„±
```

#### 1.2 LawSpecialistWorker êµ¬í˜„

```python
# agents/worker_agents/implementations/law_specialist_worker.py

from ..base.base_worker import BaseWorkerAgent
from graph_db.services.neo4j_service import Neo4jService
from graph_db.algorithms.repository.law_repository import LawRepository
from graph_db.algorithms.core.semantic_rne import SemanticRNE
from graph_db.algorithms.core.semantic_ine import SemanticINE
from sentence_transformers import SentenceTransformer

class LawSpecialistWorker(BaseWorkerAgent):
    """
    ë²•ë¥  ì „ë¬¸ê°€ ì—ì´ì „íŠ¸

    ì—­í• :
    - ë²•ë¥  ê²€ìƒ‰ (RNE/INE)
    - ë²•ë¥  í•´ì„ & ìë¬¸
    - ê´€ë ¨ ì¡°í•­ ì¶”ì²œ
    """

    def __init__(self, agent_card):
        super().__init__(agent_card)

        # Neo4j ì—°ê²°
        self.neo4j = Neo4jService()
        self.neo4j.connect()

        # ì„ë² ë”© ëª¨ë¸
        self.model = SentenceTransformer('jhgan/ko-sbert-sts')

        # Repository
        self.law_repo = LawRepository(self.neo4j)

        # ì•Œê³ ë¦¬ì¦˜
        self.rne = SemanticRNE(None, self.law_repo, self.model)
        self.ine = SemanticINE(None, self.law_repo, self.model)

    def get_system_prompt(self) -> str:
        return """ë‹¹ì‹ ì€ ë²•ë¥  ì „ë¬¸ê°€ ì—ì´ì „íŠ¸ì…ë‹ˆë‹¤.

ì—­í• :
1. ë²•ë¥  ê²€ìƒ‰: ì‚¬ìš©ì ì§ˆë¬¸ì— ê´€ë ¨ëœ ë²•ë¥ /ì‹œí–‰ë ¹/ì‹œí–‰ê·œì¹™ ì¡°í•­ ì°¾ê¸°
2. ë²•ë¥  í•´ì„: ì°¾ì€ ì¡°í•­ì„ ì´í•´í•˜ê¸° ì‰½ê²Œ ì„¤ëª…
3. ë§¥ë½ ì œê³µ: ìƒìœ„/í•˜ìœ„ ì¡°í•­, ê´€ë ¨ ë²•ê·œ ì œì‹œ

ê²€ìƒ‰ ì „ëµ:
- ì •í™•ë„ ìš°ì„ : RNE ì•Œê³ ë¦¬ì¦˜ (threshold=0.75)
- ì¬í˜„ìœ¨ ìš°ì„ : INE ì•Œê³ ë¦¬ì¦˜ (k=15)
- ìë™ ì„ íƒ: ì§ˆë¬¸ ìœ í˜•ì— ë”°ë¼

ì‘ë‹µ í˜•ì‹:
1. ê´€ë ¨ ì¡°í•­ ìš”ì•½
2. ìƒì„¸ ì„¤ëª…
3. ì°¸ê³  ì¡°í•­ (ì„ íƒ)
"""

    async def process_message(self, message: str, context_id: str, session_id: str) -> str:
        """ë²•ë¥  ê²€ìƒ‰ + í•´ì„"""

        # [1] ì¿¼ë¦¬ ë¶„ë¥˜
        query_type = self._classify_query(message)

        # [2] ê²€ìƒ‰ ì‹¤í–‰
        if query_type == "precise":
            # ì •í™•í•œ ì¡°í•­ ì°¾ê¸°
            results, _ = self.rne.execute_query(
                query_text=message,
                similarity_threshold=0.75,
                max_results=10
            )
        else:
            # ê´€ë ¨ ì¡°í•­ ì „ë¶€ ì°¾ê¸°
            results = self.ine.execute_query(
                query_text=message,
                k=15
            )

        # [3] LLMìœ¼ë¡œ í•´ì„ ìƒì„±
        context = self._format_search_results(results)
        response = await self._generate_interpretation(message, context)

        return response

    def _classify_query(self, message: str) -> str:
        """ì¿¼ë¦¬ ìœ í˜• ë¶„ë¥˜"""
        if "ì •í™•íˆ" in message or "êµ¬ì²´ì ìœ¼ë¡œ" in message:
            return "precise"  # RNE
        else:
            return "comprehensive"  # INE

    def _format_search_results(self, results) -> str:
        """ê²€ìƒ‰ ê²°ê³¼ í¬ë§·íŒ…"""
        formatted = "### ê´€ë ¨ ë²•ê·œ\n\n"

        # ë²•ê·œë³„ ê·¸ë£¹í™”
        law_groups = {}
        for r in results:
            law_name = r['law_name']
            if 'ì‹œí–‰ê·œì¹™' in law_name:
                law_type = 'ì‹œí–‰ê·œì¹™'
            elif 'ì‹œí–‰ë ¹' in law_name:
                law_type = 'ì‹œí–‰ë ¹'
            else:
                law_type = 'ë²•ë¥ '

            if law_type not in law_groups:
                law_groups[law_type] = []
            law_groups[law_type].append(r)

        # ì¶œë ¥
        for law_type in ['ë²•ë¥ ', 'ì‹œí–‰ë ¹', 'ì‹œí–‰ê·œì¹™']:
            if law_type in law_groups:
                formatted += f"\n**{law_type}**:\n"
                for article in law_groups[law_type][:3]:  # ìƒìœ„ 3ê°œ
                    formatted += f"- {article['full_id']}\n"
                    formatted += f"  {article['content'][:100]}...\n"

        return formatted

    async def _generate_interpretation(self, query: str, context: str) -> str:
        """LLMìœ¼ë¡œ í•´ì„ ìƒì„±"""
        # LangGraph ë˜ëŠ” ì§ì ‘ OpenAI API í˜¸ì¶œ
        # ê¸°ì¡´ BaseWorkerAgentì˜ LLM í˜¸ì¶œ ë©”ì»¤ë‹ˆì¦˜ í™œìš©

        prompt = f"""ì‚¬ìš©ì ì§ˆë¬¸: {query}

{context}

ìœ„ ë²•ê·œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ì ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”."""

        # LLM í˜¸ì¶œ (ê¸°ì¡´ ë©”ì»¤ë‹ˆì¦˜ ì‚¬ìš©)
        response = await self._call_llm(prompt)
        return response
```

#### 1.3 Agent Card ì‘ì„±

```json
// agents/worker_agents/cards/law_specialist_agent.json
{
  "name": "LawSpecialist",
  "slug": "law-specialist",
  "version": "1.0.0",
  "description": "ë²•ë¥  ê²€ìƒ‰ ë° í•´ì„ ì „ë¬¸ê°€",
  "capabilities": [
    {
      "name": "ë²•ë¥  ê²€ìƒ‰",
      "description": "RNE/INE ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ ê´€ë ¨ ë²•ê·œ ê²€ìƒ‰"
    },
    {
      "name": "ë²•ë¥  í•´ì„",
      "description": "ë²•ë¥  ì¡°í•­ì„ ì´í•´í•˜ê¸° ì‰½ê²Œ ì„¤ëª…"
    },
    {
      "name": "ê´€ë ¨ ì¡°í•­ ì¶”ì²œ",
      "description": "ìƒìœ„/í•˜ìœ„ ë²•ê·œ ìë™ ì¶”ì²œ"
    }
  ],
  "keywords": ["ë²•ë¥ ", "ë²•ê·œ", "ì¡°í•­", "ì‹œí–‰ë ¹", "ì‹œí–‰ê·œì¹™"],
  "author": "System",
  "license": "MIT"
}
```

#### 1.4 Worker Factory ë“±ë¡

```python
# agents/worker_agents/worker_factory.py

from .implementations.law_specialist_worker import LawSpecialistWorker

class WorkerAgentFactory:
    WORKER_CLASSES = {
        'general-worker': GeneralWorker,
        'flight-specialist': FlightSpecialistWorker,
        'law-specialist': LawSpecialistWorker,  # â† ì¶”ê°€
    }
```

#### 1.5 í…ŒìŠ¤íŠ¸

```python
# test_law_specialist.py

from agents.worker_agents.worker_factory import WorkerAgentFactory

# Agent ìƒì„±
factory = WorkerAgentFactory()
law_specialist = factory.create_worker('law-specialist')

# í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬
query = "ë„ì‹œê³„íš ìˆ˜ë¦½ ì ˆì°¨ê°€ ë­ì•¼?"
response = await law_specialist.process_message(query, "ctx1", "session1")

print(response)
```

**ì˜ˆìƒ ì¶œë ¥**:
```
ë„ì‹œê³„íš ìˆ˜ë¦½ ì ˆì°¨ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:

### ê´€ë ¨ ë²•ê·œ

**ë²•ë¥ **:
- êµ­í† ì˜ ê³„íš ë° ì´ìš©ì— ê´€í•œ ë²•ë¥ ::ì œ13ì¡°::2
  ë„ì‹œê³„íšì€ êµ­í† êµí†µë¶€ì¥ê´€ì´ ìˆ˜ë¦½í•œë‹¤...

**ì‹œí–‰ë ¹**:
- êµ­í† ì˜ ê³„íš ë° ì´ìš©ì— ê´€í•œ ë²•ë¥  ì‹œí–‰ë ¹::ì œ6ì¡°ì˜2::1
  ë²• ì œ13ì¡°ì— ë”°ë¥¸ ë„ì‹œê³„íš ìˆ˜ë¦½ ì‹œ ë‹¤ìŒ ì ˆì°¨ë¥¼ ë”°ë¥¸ë‹¤...

**ì‹œí–‰ê·œì¹™**:
- êµ­í† ì˜ ê³„íš ë° ì´ìš©ì— ê´€í•œ ë²•ë¥  ì‹œí–‰ê·œì¹™::ì œ3ì¡°::â‘ 
  ì˜ ì œ25ì¡°ì œ3í•­ì œ1í˜¸ë‹¤ëª©ì—ì„œ ì •í•˜ëŠ” ê²½ë¯¸í•œ ì‚¬í•­...

### ìƒì„¸ ì„¤ëª…
ë„ì‹œê³„íšì€ ë¨¼ì € ë²•ë¥ ì—ì„œ í° í‹€ì„ ì •í•˜ê³ , ì‹œí–‰ë ¹ì—ì„œ êµ¬ì²´ì ì¸ ì ˆì°¨ë¥¼,
ì‹œí–‰ê·œì¹™ì—ì„œ ì„¸ë¶€ ì‚¬í•­ì„ ê·œì •í•©ë‹ˆë‹¤...
```

---

### Phase 2: ëŒ€ëŸ‰ PDF ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ (2ì£¼)

**ëª©í‘œ**: ìˆ˜ì²œ ê°œ PDF ìë™ ì²˜ë¦¬

#### 2.1 í´ë” êµ¬ì¡°

```
law/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                    # ì›ë³¸ PDF (ìˆ˜ì²œ ê°œ)
â”‚   â”‚   â”œâ”€â”€ batch_001/
â”‚   â”‚   â”‚   â”œâ”€â”€ law_001.pdf
â”‚   â”‚   â”‚   â”œâ”€â”€ law_002.pdf
â”‚   â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚   â”œâ”€â”€ batch_002/
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚
â”‚   â”œâ”€â”€ parsed/                 # íŒŒì‹±ëœ JSON
â”‚   â”‚   â”œâ”€â”€ law_001.json
â”‚   â”‚   â”œâ”€â”€ law_002.json
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚
â”‚   â””â”€â”€ embeddings/             # ì„ë² ë”© ìºì‹œ
â”‚       â”œâ”€â”€ law_001_embeddings.pkl
â”‚       â””â”€â”€ ...
â”‚
â””â”€â”€ scripts/
    â”œâ”€â”€ batch_processor.py      # â† ìƒˆë¡œ ìƒì„± (ë°°ì¹˜ ì²˜ë¦¬)
    â”œâ”€â”€ pdf_to_json_batch.py    # â† ìƒˆë¡œ ìƒì„± (ë³‘ë ¬ PDFâ†’JSON)
    â””â”€â”€ json_to_neo4j_batch.py  # â† ìƒˆë¡œ ìƒì„± (ë°°ì¹˜ Neo4j ì‚½ì…)
```

#### 2.2 ë°°ì¹˜ ì²˜ë¦¬ ìŠ¤í¬ë¦½íŠ¸

```python
# law/scripts/batch_processor.py
"""
ëŒ€ëŸ‰ PDF ì¼ê´„ ì²˜ë¦¬

ë‹¨ê³„:
1. PDF â†’ JSON (ë³‘ë ¬ ì²˜ë¦¬)
2. JSON â†’ Neo4j (ë°°ì¹˜ ì‚½ì…)
3. ì„ë² ë”© ìƒì„± (GPU ê°€ì†)
"""

import os
import multiprocessing
from pathlib import Path
from tqdm import tqdm

class LawBatchProcessor:
    def __init__(self, raw_dir, parsed_dir, batch_size=100):
        self.raw_dir = Path(raw_dir)
        self.parsed_dir = Path(parsed_dir)
        self.batch_size = batch_size

    def process_all(self):
        """ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""

        # [1] PDF â†’ JSON (ë³‘ë ¬)
        pdf_files = list(self.raw_dir.rglob("*.pdf"))
        print(f"ë°œê²¬í•œ PDF: {len(pdf_files)}ê°œ")

        with multiprocessing.Pool() as pool:
            results = list(tqdm(
                pool.imap(self._process_single_pdf, pdf_files),
                total=len(pdf_files),
                desc="PDF íŒŒì‹±"
            ))

        # [2] JSON â†’ Neo4j (ë°°ì¹˜)
        json_files = list(self.parsed_dir.glob("*.json"))
        self._batch_import_to_neo4j(json_files)

        # [3] ì„ë² ë”© ìƒì„±
        self._generate_embeddings()

    def _process_single_pdf(self, pdf_path):
        """ë‹¨ì¼ PDF ì²˜ë¦¬"""
        from law.core.pdf_extractor import PDFExtractor
        from law.core.law_parser_improved import LawParser

        # PDF â†’ í…ìŠ¤íŠ¸
        extractor = PDFExtractor()
        text = extractor.extract(pdf_path)

        # í…ìŠ¤íŠ¸ â†’ JSON
        parser = LawParser()
        data = parser.parse(text)

        # JSON ì €ì¥
        output_path = self.parsed_dir / f"{pdf_path.stem}.json"
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)

        return output_path

    def _batch_import_to_neo4j(self, json_files):
        """ë°°ì¹˜ Neo4j ì‚½ì…"""
        from graph_db.services.neo4j_service import Neo4jService

        neo4j = Neo4jService()
        neo4j.connect()

        # ë°°ì¹˜ ì²˜ë¦¬ (100ê°œì”©)
        for i in tqdm(range(0, len(json_files), self.batch_size), desc="Neo4j ì‚½ì…"):
            batch = json_files[i:i+self.batch_size]

            # Cypher UNWINDë¡œ ë°°ì¹˜ ì‚½ì…
            with neo4j.driver.session() as session:
                session.run("""
                    UNWIND $batch as item
                    MERGE (law:LAW {name: item.law_name})
                    // ... (ë‚˜ë¨¸ì§€ ë…¸ë“œ ìƒì„±)
                """, batch=[self._load_json(f) for f in batch])

    def _generate_embeddings(self):
        """ì„ë² ë”© ìƒì„± (GPU ê°€ì†)"""
        from sentence_transformers import SentenceTransformer

        # GPU ì‚¬ìš© ê°€ëŠ¥ ì‹œ ìë™ í™œìš©
        model = SentenceTransformer('jhgan/ko-sbert-sts')

        # ë°°ì¹˜ ì²˜ë¦¬
        # ... (ê¸°ì¡´ add_embeddings.py ë¡œì§ í™œìš©)

# ì‹¤í–‰
if __name__ == "__main__":
    processor = LawBatchProcessor(
        raw_dir="law/data/raw",
        parsed_dir="law/data/parsed"
    )
    processor.process_all()
```

**ì‹¤í–‰**:
```bash
# ì „ì²´ PDF ì²˜ë¦¬ (ë³‘ë ¬)
python law/scripts/batch_processor.py

# ì§„í–‰ ìƒí™©
# PDF íŒŒì‹±: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5000/5000 [1:23:45<00:00, 59.82it/s]
# Neo4j ì‚½ì…: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:15:32<00:00, 18.64s/it]
# ì„ë² ë”© ìƒì„±: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5000/5000 [02:34:12<00:00, 1.85s/it]
```

#### 2.3 ì„±ëŠ¥ ìµœì í™”

**ë³‘ë ¬ ì²˜ë¦¬**:
```python
# CPU ì½”ì–´ í™œìš©
cpu_count = multiprocessing.cpu_count()
with multiprocessing.Pool(processes=cpu_count - 1) as pool:
    pool.map(process_pdf, pdf_files)
```

**GPU ê°€ì†** (ì„ íƒ):
```python
# CUDA ì‚¬ìš© ê°€ëŠ¥ ì‹œ ìë™ í™œìš©
model = SentenceTransformer('jhgan/ko-sbert-sts', device='cuda')

# ë°°ì¹˜ ì„ë² ë”© (ë” ë¹ ë¦„)
embeddings = model.encode(texts, batch_size=32, show_progress_bar=True)
```

**ìºì‹±**:
```python
# ì´ë¯¸ ì²˜ë¦¬ëœ íŒŒì¼ ìŠ¤í‚µ
def is_already_processed(pdf_path, parsed_dir):
    json_path = parsed_dir / f"{pdf_path.stem}.json"
    return json_path.exists()

pdf_files = [f for f in all_pdfs if not is_already_processed(f, parsed_dir)]
```

---

### Phase 3: A2A í†µí•© & ë¼ìš°íŒ… (1ì£¼)

**ëª©í‘œ**: GeneralWorkerê°€ ë²•ë¥  ì§ˆë¬¸ì„ LawSpecialistì—ê²Œ ìë™ ë¼ìš°íŒ…

#### 3.1 ë¼ìš°íŒ… ê·œì¹™

```python
# agents/worker_agents/implementations/general_worker.py

class GeneralWorker(BaseWorkerAgent):
    async def process_message(self, message, context_id, session_id):
        # ë²•ë¥  ê´€ë ¨ í‚¤ì›Œë“œ ê°ì§€
        law_keywords = ['ë²•ë¥ ', 'ë²•ê·œ', 'ì¡°í•­', 'ì‹œí–‰ë ¹', 'ì‹œí–‰ê·œì¹™',
                       'ê·œì •', 'ë²•', 'ì¡°ë¡€', 'ì‹œí–‰', 'ê°œì •']

        if any(keyword in message for keyword in law_keywords):
            # LawSpecialistì—ê²Œ ìœ„ì„
            return await self._delegate_to_specialist(
                'law-specialist',
                message,
                context_id
            )

        # ê¸°ì¡´ ë¡œì§...
```

#### 3.2 A2A ë©”ì‹œì§€ íë¦„

```
[ì‚¬ìš©ì]
"ë„ì‹œê³„íš ë²•ê·œ ì•Œë ¤ì¤˜"
  â†“ WebSocket
[GeneralWorker]
  â†“ í‚¤ì›Œë“œ ê°ì§€: "ë²•ê·œ"
  â†“ A2A JSON-RPC
  {
    "jsonrpc": "2.0",
    "method": "process_message",
    "params": {
      "message": "ë„ì‹œê³„íš ë²•ê·œ ì•Œë ¤ì¤˜",
      "context_id": "ctx123"
    }
  }
  â†“
[LawSpecialist]
  â†“ RNE ê²€ìƒ‰
  â†“ Neo4j
  â†“ LLM í•´ì„
  {
    "result": "ë„ì‹œê³„íš ë²•ê·œëŠ”..."
  }
  â†“ A2A ì‘ë‹µ
[GeneralWorker]
  â†“ í¬ë§·íŒ…
[ì‚¬ìš©ì]
```

---

### Phase 4: Context7 & Web ê²€ìƒ‰ í†µí•© (1ì£¼)

**ëª©í‘œ**: ì™¸ë¶€ ì§€ì‹ê³¼ ë‚´ë¶€ ë²•ë¥  DB ê²°í•©

#### 4.1 í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰

```python
# agents/worker_agents/implementations/law_specialist_worker.py

class LawSpecialistWorker(BaseWorkerAgent):
    async def process_message(self, message, context_id, session_id):
        # [1] ë‚´ë¶€ ë²•ë¥  DB ê²€ìƒ‰ (RNE/INE)
        internal_results = self.rne.execute_query(message, threshold=0.75)

        # [2] Context7 ê²€ìƒ‰ (ì™¸ë¶€ ë²•ë¥  ë°ì´í„°ë² ì´ìŠ¤)
        external_results = await self._search_context7(message)

        # [3] Web ê²€ìƒ‰ (ìµœì‹  íŒë¡€, í•´ì„)
        web_results = await self._search_web(message)

        # [4] ê²°í•© & ë­í‚¹
        combined = self._merge_results(
            internal_results,
            external_results,
            web_results
        )

        # [5] LLM í•´ì„
        response = await self._generate_interpretation(message, combined)
        return response

    async def _search_context7(self, query):
        """Context7 API í˜¸ì¶œ"""
        # ê¸°ì¡´ Context7 MCP ì„œë²„ í™œìš©
        # mcp__context7__get-library-docs í˜¸ì¶œ
        pass

    async def _search_web(self, query):
        """Web ê²€ìƒ‰"""
        # WebSearch ë„êµ¬ í™œìš©
        pass

    def _merge_results(self, internal, external, web):
        """ê²°ê³¼ ë³‘í•© & ì¤‘ë³µ ì œê±°"""
        # ìœ ì‚¬ë„ ê¸°ë°˜ ì¤‘ë³µ ì œê±°
        # ì†ŒìŠ¤ë³„ ê°€ì¤‘ì¹˜ ì ìš©
        pass
```

#### 4.2 ì†ŒìŠ¤ë³„ ê°€ì¤‘ì¹˜

```python
WEIGHTS = {
    'internal_law': 1.0,      # ë‚´ë¶€ ë²•ë¥  DB (ê°€ì¥ ì‹ ë¢°)
    'context7': 0.8,          # Context7 (ì „ë¬¸ DB)
    'web_search': 0.5,        # Web ê²€ìƒ‰ (ì°¸ê³ ìš©)
}

def _merge_results(self, internal, external, web):
    merged = []

    for result in internal:
        result['score'] *= WEIGHTS['internal_law']
        result['source'] = 'internal'
        merged.append(result)

    for result in external:
        result['score'] *= WEIGHTS['context7']
        result['source'] = 'context7'
        merged.append(result)

    for result in web:
        result['score'] *= WEIGHTS['web_search']
        result['source'] = 'web'
        merged.append(result)

    # ìœ ì‚¬ë„ ê¸°ë°˜ ì¤‘ë³µ ì œê±°
    merged = self._deduplicate(merged)

    # ì ìˆ˜ìˆœ ì •ë ¬
    merged.sort(key=lambda x: x['score'], reverse=True)

    return merged[:15]  # Top-15
```

---

### Phase 5: í™•ì¥ & ìµœì í™” (ì§„í–‰ì¤‘)

**ëª©í‘œ**: ëŒ€ê·œëª¨ ìš´ì˜ ì¤€ë¹„

#### 5.1 ë²¡í„° DB ë§ˆì´ê·¸ë ˆì´ì…˜ (ì„ íƒ)

**ë¬¸ì œ**: Neo4j ë²¡í„° ì¸ë±ìŠ¤ëŠ” ëŒ€ê·œëª¨ ë°ì´í„°ì—ì„œ ëŠë¦´ ìˆ˜ ìˆìŒ

**í•´ê²°**: Qdrant/Pinecone ë“± ì „ë¬¸ ë²¡í„° DB í™œìš©

```python
from qdrant_client import QdrantClient

class LawRepository:
    def __init__(self, neo4j, qdrant):
        self.neo4j = neo4j      # ê·¸ë˜í”„ êµ¬ì¡°
        self.qdrant = qdrant    # ë²¡í„° ê²€ìƒ‰

    def vector_search(self, query_emb, top_k):
        # Qdrantë¡œ ë¹ ë¥¸ ë²¡í„° ê²€ìƒ‰
        results = self.qdrant.search(
            collection_name="law_embeddings",
            query_vector=query_emb,
            limit=top_k
        )

        # Neo4jì—ì„œ ê·¸ë˜í”„ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        for result in results:
            hang_id = result.id
            neighbors = self._get_neighbors_from_neo4j(hang_id)
            result.neighbors = neighbors

        return results
```

#### 5.2 ìºì‹± ì „ëµ

```python
import redis
import pickle

class CachedLawRepository:
    def __init__(self, law_repo):
        self.law_repo = law_repo
        self.redis = redis.Redis()
        self.ttl = 3600  # 1ì‹œê°„

    def vector_search(self, query_emb, top_k):
        # ìºì‹œ í‚¤
        cache_key = f"search:{hash(query_emb.tobytes())}:{top_k}"

        # ìºì‹œ í™•ì¸
        cached = self.redis.get(cache_key)
        if cached:
            return pickle.loads(cached)

        # ê²€ìƒ‰ ì‹¤í–‰
        results = self.law_repo.vector_search(query_emb, top_k)

        # ìºì‹œ ì €ì¥
        self.redis.setex(cache_key, self.ttl, pickle.dumps(results))

        return results
```

#### 5.3 ëª¨ë‹ˆí„°ë§

```python
# ê²€ìƒ‰ ë¡œê·¸
import logging

logger = logging.getLogger('law_search')

def vector_search(self, query_emb, top_k):
    import time
    start = time.time()

    results = self._do_search(query_emb, top_k)

    elapsed = time.time() - start
    logger.info(f"ê²€ìƒ‰ ì™„ë£Œ: {len(results)}ê°œ, {elapsed:.2f}ì´ˆ")

    # ë©”íŠ¸ë¦­ ìˆ˜ì§‘
    metrics.record('search_latency', elapsed)
    metrics.record('search_results', len(results))

    return results
```

---

## ğŸ“ˆ ì˜ˆìƒ íš¨ê³¼

### 1. ê²€ìƒ‰ ì„±ëŠ¥

| í•­ëª© | í˜„ì¬ (3 PDF) | Phase 2 (5,000 PDF) | ê°œì„ ìœ¨ |
|------|--------------|---------------------|--------|
| ë²•ê·œ ì»¤ë²„ë¦¬ì§€ | 3ê°œ | 5,000+ê°œ | **+166,567%** |
| HANG ë…¸ë“œ | 2,987ê°œ | ~500,000ê°œ | **+16,633%** |
| ê²€ìƒ‰ ì •í™•ë„ | 88% | 92% (ì˜ˆìƒ) | +4.5% |

### 2. ì‚¬ìš©ì ê²½í—˜

**Before (í˜„ì¬)**:
```
ì‚¬ìš©ì: "ë„ì‹œê³„íš ë²•ê·œ ì•Œë ¤ì¤˜"
ì‹œìŠ¤í…œ: (ì‘ë‹µ ì—†ìŒ - MASì™€ ë¶„ë¦¬ë¨)
```

**After (Phase 3 ì™„ë£Œ)**:
```
ì‚¬ìš©ì: "ë„ì‹œê³„íš ë²•ê·œ ì•Œë ¤ì¤˜"
GeneralWorker: (ë²•ë¥  í‚¤ì›Œë“œ ê°ì§€)
  â†“ A2A
LawSpecialist: (RNE ê²€ìƒ‰)
  â†’ ë²•ë¥  3ê°œ, ì‹œí–‰ë ¹ 2ê°œ, ì‹œí–‰ê·œì¹™ 5ê°œ ë°œê²¬
  â†’ LLM í•´ì„ ìƒì„±
ì‹œìŠ¤í…œ: "ë„ì‹œê³„íš ë²•ê·œëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤..."
```

### 3. í™•ì¥ ê°€ëŠ¥ì„±

```
í˜„ì¬ ì‹œìŠ¤í…œ:
  â””â”€ ë²•ë¥  ê²€ìƒ‰ (ë…ë¦½)

Phase 5 ì™„ë£Œ:
  â”œâ”€ ë²•ë¥  ê²€ìƒ‰ (RNE/INE)
  â”œâ”€ íŒë¡€ ê²€ìƒ‰ (ì¶”ê°€ ê°€ëŠ¥)
  â”œâ”€ í–‰ì • ê·œì¹™ ê²€ìƒ‰ (ì¶”ê°€ ê°€ëŠ¥)
  â””â”€ ì™¸êµ­ ë²•ë¥  ê²€ìƒ‰ (Context7)
```

---

## ğŸš€ ì‹œì‘ ë°©ë²•

### Quick Start (Phase 1ë§Œ ë¨¼ì €)

```bash
# 1. LawSpecialist íŒŒì¼ ìƒì„±
mkdir -p agents/worker_agents/implementations
touch agents/worker_agents/implementations/law_specialist_worker.py

mkdir -p agents/worker_agents/cards
touch agents/worker_agents/cards/law_specialist_agent.json

# 2. êµ¬í˜„ (ìœ„ ì½”ë“œ ë³µì‚¬)
# ... (law_specialist_worker.py, law_specialist_agent.json ì‘ì„±)

# 3. Worker Factory ë“±ë¡
# agents/worker_agents/worker_factory.py ìˆ˜ì •

# 4. í…ŒìŠ¤íŠ¸
python test_law_specialist.py

# 5. MAS í†µí•© í…ŒìŠ¤íŠ¸
daphne -b 0.0.0.0 -p 8000 backend.asgi:application
# ë¸Œë¼ìš°ì €: http://localhost:8000/chat/
# ë©”ì‹œì§€: "ë„ì‹œê³„íš ë²•ê·œ ì•Œë ¤ì¤˜"
```

---

## ğŸ¯ íƒ€ì„ë¼ì¸

| Phase | ê¸°ê°„ | í•µì‹¬ ì‘ì—… | ìš°ì„ ìˆœìœ„ |
|-------|------|----------|---------|
| Phase 1 | 1ì£¼ | LawSpecialist Agent | â­â­â­â­â­ |
| Phase 2 | 2ì£¼ | ëŒ€ëŸ‰ PDF ì²˜ë¦¬ | â­â­â­â­ |
| Phase 3 | 1ì£¼ | A2A ë¼ìš°íŒ… | â­â­â­â­â­ |
| Phase 4 | 1ì£¼ | Context7/Web í†µí•© | â­â­â­ |
| Phase 5 | ì§„í–‰ì¤‘ | í™•ì¥ & ìµœì í™” | â­â­ |

**ì´ ì†Œìš” ì‹œê°„**: 5ì£¼

**ìµœì†Œ MVP (Phase 1+3)**: 2ì£¼

---

## ğŸ¤” ì˜ì‚¬ ê²°ì • í¬ì¸íŠ¸

### 1. ë²¡í„° DB ì„ íƒ

**ì„ íƒì§€**:
- A. Neo4j ë²¡í„° ì¸ë±ìŠ¤ (í˜„ì¬)
- B. Qdrant (ì „ë¬¸ ë²¡í„° DB)
- C. Pinecone (í´ë¼ìš°ë“œ)

**ì¶”ì²œ**: Phase 2ì—ì„œ ë°ì´í„° ê·œëª¨ í™•ì¸ í›„ ê²°ì •

### 2. ì„ë² ë”© ëª¨ë¸

**ì„ íƒì§€**:
- A. ko-sbert-sts (í˜„ì¬, 768-dim)
- B. ko-sroberta-multitask (1024-dim)
- C. multilingual-e5 (1024-dim)

**ì¶”ì²œ**: í˜„ì¬ ëª¨ë¸ ìœ ì§€, Phase 5ì—ì„œ ì„±ëŠ¥ ë¹„êµ

### 3. LLM ì„ íƒ

**ì„ íƒì§€**:
- A. OpenAI GPT-4 (ê¸°ì¡´)
- B. Claude 3.5 Sonnet
- C. Gemini 2.0

**ì¶”ì²œ**: Phase 4ì—ì„œ ë²•ë¥  í•´ì„ í’ˆì§ˆ ë¹„êµ

---

## ğŸ“š ì°¸ê³  ìë£Œ

- [2025-10-31-RNE_INE_INTEGRATION_GUIDE.md](./2025-10-31-RNE_INE_INTEGRATION_GUIDE.md)
- [2025-10-31-CROSS_LAW_VERIFICATION_COMPLETE.md](./2025-10-31-CROSS_LAW_VERIFICATION_COMPLETE.md)
- [CLAUDE.md](../CLAUDE.md) - MAS ì•„í‚¤í…ì²˜

---

**ì‘ì„±ì¼**: 2025-10-31
**ì‘ì„±ì**: Claude Code
**ë‹¤ìŒ ì‘ì—…**: Phase 1 - LawSpecialist Agent ê°œë°œ
